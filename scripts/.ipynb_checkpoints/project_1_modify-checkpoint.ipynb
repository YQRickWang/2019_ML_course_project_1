{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input train data from csv\n",
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'D:\\\\Jupyter Notebook\\Machine Learning\\project1\\data\\\\train.csv'  \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000,), (250000, 30), (250000,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of y,tX,ids\n",
    "y.shape,tX.shape,ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 import some functions and make some settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_x(p_t,phi):\n",
    "    px = p_t*np.cos(phi)\n",
    "    return px\n",
    "\n",
    "def p_y(p_t,phi):\n",
    "    py = p_t*np.sin(phi)\n",
    "    return py\n",
    "\n",
    "def p_z(p_t,eta):\n",
    "    pz = p_t*np.sinh(eta)\n",
    "    return pz\n",
    "\n",
    "#mass are neglected, E = p\n",
    "def particle_energy(px,py,pz):\n",
    "    energy = np.sqrt(px**2+py**2+pz**2)\n",
    "    return energy\n",
    "\n",
    "def cross_product(px_1,py_1,pz_1,px_2,py_2,pz_2):\n",
    "    N = len(px_1)\n",
    "    cp_x = np.zeros(N)\n",
    "    cp_y = np.zeros(N)\n",
    "    cp_z = np.zeros(N)\n",
    "    for t in range(N):\n",
    "        temp_cross=np.cross(np.array([px_1[t],py_1[t],pz_1[t]]),np.array([px_2[t],py_2[t],pz_2[t]]))\n",
    "        cp_x[t] = temp_cross[0]\n",
    "        cp_y[t] = temp_cross[1]\n",
    "        cp_z[t] = temp_cross[2]\n",
    "    return cp_x,cp_y,cp_z\n",
    "\n",
    "def dot_product(px_1,py_1,pz_1,px_2,py_2,pz_2):\n",
    "    N = len(px_1)\n",
    "    dp = np.zeros(N)\n",
    "    for t in range(N):\n",
    "        dp[t] = np.inner(np.array([px_1[t],py_1[t],pz_1[t]]),np.array([px_2[t],py_2[t],pz_2[t]]))\n",
    "    return dp\n",
    "\n",
    "def cosine_similarity(px_1,py_1,pz_1,px_2,py_2,pz_2):\n",
    "    cp = dot_product(px_1,py_1,pz_1,px_2,py_2,pz_2)/(np.sqrt(px_1**2+py_1**2+pz_1**2)*np.sqrt(px_2**2+py_2**2+pz_2**2))\n",
    "    \n",
    "    return cp\n",
    "\n",
    "def determinant_vector(px_1,py_1,pz_1,px_2,py_2,pz_2,px_3,py_3,pz_3):\n",
    "    N = len(px_1)\n",
    "    dv = np.zeros(N)\n",
    "    for t in range(N):\n",
    "        temp_vector = np.array([[px_1[t],py_1[t],pz_1[t]],[px_2[t],py_2[t],pz_2[t]],[px_3[t],py_3[t],pz_3[t]]])\n",
    "        dv[t] = np.linalg.det(temp_vector)\n",
    "\n",
    "    return dv\n",
    "\n",
    "def sum_p_xyz(px,py,pz):\n",
    "    sp = px+py+pz\n",
    "    return sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the name of each feature\n",
    "# DER_mass_MMC = tX[:,0]\n",
    "# DER_mass_transverse_met_lep=tX[:,1]\n",
    "# DER_mass_vis = tX[:,2]\n",
    "# DER_pt_h = tX[:,3]\n",
    "# DER_deltaeta_jet_jet = tX[:,4]\n",
    "# DER_mass_jet_jet = tX[:,5]\n",
    "# DER_prodeta_jet_jet = tX[:,6]\n",
    "# DER_deltar_tau_lep = tX[:,7]\n",
    "# DER_pt_tot = tX[:,8]\n",
    "# DER_sum_pt = tX[:,9]\n",
    "# DER_pt_ratio_lep_tau = tX[:,10]\n",
    "# DER_met_phi_centrality = tX[:,11]\n",
    "# DER_lep_eta_centrality = tX[:,12]\n",
    "# PRI_tau_pt = tX[:,13]\n",
    "# PRI_tau_eta = tX[:,14]\n",
    "# PRI_tau_phi = tX[:,15]\n",
    "# PRI_lep_pt = tX[:,16]\n",
    "# PRI_lep_eta =tX[:,17]\n",
    "# PRI_lep_phi = tX[:,18]\n",
    "# PRI_met=tX[:,19]\n",
    "# PRI_met_phi = tX[:,20]\n",
    "# PRI_met_sumet = tX[:,21]\n",
    "# PRI_jet_num=tX[:,22]\n",
    "# PRI_jet_leading_pt=tX[:,23]\n",
    "# PRI_jet_leading_eta = tX[:,24]\n",
    "# PRI_jet_leading_phi = tX[:,25]\n",
    "# PRI_jet_subleading_pt=tX[:,26]\n",
    "# PRI_jet_subleading_eta = tX[:,27]\n",
    "# PRI_jet_subleading_phi = tX[:,28]\n",
    "# PRI_jet_all_pt = tX[:,29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 generate some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate px,py,pz and append to the tX\n",
    "#tau\n",
    "p_tau_x = p_x(PRI_tau_pt,PRI_tau_phi)\n",
    "p_tau_y = p_y(PRI_tau_pt,PRI_tau_phi)\n",
    "p_tau_z = p_z(PRI_tau_pt,PRI_tau_eta)\n",
    "#lep\n",
    "p_lep_x = p_x(PRI_lep_pt,PRI_lep_phi)\n",
    "p_lep_y = p_y(PRI_lep_pt,PRI_lep_phi)\n",
    "p_lep_z = p_z(PRI_lep_pt,PRI_lep_eta)\n",
    "#met\n",
    "p_met_x = p_x(PRI_met,PRI_met_phi)\n",
    "p_met_y = p_y(PRI_met,PRI_met_phi)\n",
    "\n",
    "#append features\n",
    "tX=np.append(tX,np.array([p_tau_x,p_tau_y,p_tau_z,p_lep_x,p_lep_y,p_lep_z,p_met_x,p_met_y]).T,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate energy of particle\n",
    "p_tau_energy = particle_energy(p_tau_x,p_tau_y,p_tau_z)\n",
    "p_lep_energy = particle_energy(p_lep_x,p_lep_y,p_lep_z)\n",
    "\n",
    "#append features\n",
    "tX=np.append(tX,np.array([p_tau_energy,p_lep_energy]).T,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(y)\n",
    "#vector product\n",
    "#tau-lep\n",
    "\n",
    "tau_lep_dot = dot_product(p_tau_x,p_tau_y,p_tau_z,p_lep_x,p_lep_y,p_lep_z)\n",
    "tau_lep_cross_x,tau_lep_cross_y,tau_lep_cross_z = cross_product(p_tau_x,p_tau_y,p_tau_z,p_lep_x,p_lep_y,p_lep_z)\n",
    "tau_lep_cosine_similarity = cosine_similarity(p_tau_x,p_tau_y,p_tau_z,p_lep_x,p_lep_y,p_lep_z)\n",
    "\n",
    "#tau-met\n",
    "tau_met_dot = dot_product(p_tau_x,p_tau_y,p_tau_z,p_met_x,p_met_y,np.zeros(N))\n",
    "tau_met_cross_x,tau_met_cross_y,tau_met_cross_z = cross_product(p_tau_x,p_tau_y,p_tau_z,p_met_x,p_met_y,np.zeros(N))\n",
    "tau_met_cosine_similarity =cosine_similarity(p_tau_x,p_tau_y,p_tau_z,p_met_x,p_met_y,np.zeros(N))\n",
    "#lep-met\n",
    "lep_met_dot = dot_product(p_lep_x,p_lep_y,p_lep_z,p_met_x,p_met_y,np.zeros(N))\n",
    "lep_met_cross_x,lep_met_cross_y,lep_met_cross_z = cross_product(p_lep_x,p_lep_y,p_lep_z,p_met_x,p_met_y,np.zeros(N))\n",
    "lep_met_cosine_similarity =cosine_similarity(p_lep_x,p_lep_y,p_lep_z,p_met_x,p_met_y,np.zeros(N))\n",
    "\n",
    "#append features\n",
    "tX=np.append(tX,np.array([tau_lep_dot,tau_lep_cross_x,tau_lep_cross_y,tau_lep_cross_z,tau_lep_cosine_similarity]).T,axis=1)\n",
    "tX=np.append(tX,np.array([tau_met_dot,tau_met_cross_x,tau_met_cross_y,tau_met_cross_z,tau_met_cosine_similarity]).T,axis=1)\n",
    "tX=np.append(tX,np.array([lep_met_dot,lep_met_cross_x,lep_met_cross_y,lep_met_cross_z,lep_met_cosine_similarity]).T,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate determinant vector\n",
    "d_vector = determinant_vector(p_tau_x,p_tau_y,p_tau_z,p_lep_x,p_lep_y,p_lep_z,p_met_x,p_met_y,np.zeros(N))\n",
    "\n",
    "#append features\n",
    "tX=np.append(tX,np.array([d_vector]).T,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 cross-validation function and indice function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y,tX,k_indices,k):\n",
    "    \n",
    "    tX_test_indice = k_indices[k]\n",
    "    tX_train_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tX_train_indice = tX_train_indice.reshape(-1)\n",
    "    y_test = y[tX_test_indice]\n",
    "    y_train = y[tX_train_indice]\n",
    "    tX_test = tX[tX_test_indice]\n",
    "    tX_train = tX[tX_train_indice]\n",
    "    \n",
    "    #split train and test into four groups\n",
    "    y_train_0,y_train_1,y_train_2,y_train_3,y_test_0,y_test_1,y_test_2,y_test_3,tX_train_0,tX_train_1,tX_train_2,tX_train_3,tX_test_0,tX_test_1,tX_test_2,tX_test_3=split_groups(y_train,y_test,tX_train,tX_test)\n",
    "    \n",
    "    \n",
    "    weight_0 = ridge_regression(y_train_0,tX_train_0,0.01)\n",
    "    weight_1 = ridge_regression(y_train_1,tX_train_1,0.01)\n",
    "    weight_2 = ridge_regression(y_train_2,tX_train_2,0.01)\n",
    "    weight_3 = ridge_regression(y_train_3,tX_train_3,0.01)\n",
    "    \n",
    "    y_pred_0 = predict_labels(weight_0, tX_test_0)\n",
    "    y_pred_1 = predict_labels(weight_1, tX_test_1)\n",
    "    y_pred_2 = predict_labels(weight_2, tX_test_2)\n",
    "    y_pred_3 = predict_labels(weight_3, tX_test_3)\n",
    "    \n",
    "    num_0 = np.count_nonzero(y_pred_0==y_test_0)\n",
    "    num_1 = np.count_nonzero(y_pred_1==y_test_1)\n",
    "    num_2 = np.count_nonzero(y_pred_2==y_test_2)\n",
    "    num_3 = np.count_nonzero(y_pred_3==y_test_3)\n",
    "    \n",
    "    num = len(y_test)\n",
    "    accuracy = (num_0+num_1+num_2+num_3)/num\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def split_groups(y_train,y_test,tX_train,tX_test):\n",
    "    tX_train_jet_num = tX_train[:,22]\n",
    "    tX_test_jet_num = tX_test[:,22]\n",
    "    \n",
    "    y_train_0 = np.copy(y_train[tX_train_jet_num==0])\n",
    "    y_train_1 = np.copy(y_train[tX_train_jet_num==1])\n",
    "    y_train_2 = np.copy(y_train[tX_train_jet_num==2])\n",
    "    y_train_3 = np.copy(y_train[tX_train_jet_num==3])\n",
    "    \n",
    "    y_test_0 = np.copy(y_test[tX_test_jet_num==0])\n",
    "    y_test_1 = np.copy(y_test[tX_test_jet_num==1])\n",
    "    y_test_2 = np.copy(y_test[tX_test_jet_num==2])\n",
    "    y_test_3 = np.copy(y_test[tX_test_jet_num==3])\n",
    "    \n",
    "    tX_train_0 = np.copy(tX_train[tX_train_jet_num==0])\n",
    "    tX_train_1 = np.copy(tX_train[tX_train_jet_num==1])\n",
    "    tX_train_2 = np.copy(tX_train[tX_train_jet_num==2])\n",
    "    tX_train_3 = np.copy(tX_train[tX_train_jet_num==3])\n",
    "    \n",
    "    tX_test_0 = np.copy(tX_test[tX_test_jet_num==0])\n",
    "    tX_test_1 = np.copy(tX_test[tX_test_jet_num==1])\n",
    "    tX_test_2 = np.copy(tX_test[tX_test_jet_num==2])\n",
    "    tX_test_3 = np.copy(tX_test[tX_test_jet_num==3])\n",
    "    \n",
    "    return y_train_0,y_train_1,y_train_2,y_train_3,y_test_0,y_test_1,y_test_2,y_test_3,tX_train_0,tX_train_1,tX_train_2,tX_train_3,tX_test_0,tX_test_1,tX_test_2,tX_test_3\n",
    "\n",
    "def build_k_indices(y,k_fold,seed):\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row/k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices=np.random.permutation(num_row)\n",
    "    k_indices = [indices[k*interval:(k+1)*interval] for k in range (k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    N = len(y)\n",
    "    a = tx.T.dot(tx)+lambda_*(2*N)*np.identity(tx.shape[1])\n",
    "    b = tx.T.dot(y)\n",
    "    weight = np.linalg.solve(a,b)\n",
    "    \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo():\n",
    "    k_fold = 4\n",
    "    seed = 12\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    total = 0\n",
    "    for k in range(k_fold):\n",
    "        accuracy = cross_validation(y,tX,k_indices,k)\n",
    "        total  = total+accuracy\n",
    "        print(f'{k}:{accuracy} ')\n",
    "    \n",
    "    average=total/k_fold\n",
    "    print(f'average accuracy:{accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0.75872 \n",
      "1:0.758608 \n",
      "2:0.757616 \n",
      "3:0.755632 \n",
      "average accuracy0.755632\n"
     ]
    }
   ],
   "source": [
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
